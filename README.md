# Machine Learning.

Simple and multiple linear regression

Simple Linear regression: consist of find the best-fitting straight line through the points.
Equation:
y(dependent variable) = b0 + b1 * x1(independent variable).

Example:
Salary versus experience.
The dataset contains information about the years of experience and salary from people

So, the example are going to try the simple linear regression model and draw a trend line that best fits the point at the chart.

Supervised classification: 
It is a supervised classification when the training is based on a correct label. So, when we have some set of classification known and the training is based on that, we can say it is a supervised classification.

Naive Bayes classifier
It is a algorithm for the classification. It chooses the most likely label for an input. It gives great results when it work with data text analysis.

Bayes theorem
It is the prabality somehting happen, given that something else has already ocurred.

Maximum Entropy classifier
It is similar naive bayes classifier, however it uses technique to find a set of parameters that maximize the total likehood of the training corpus.

It is important to know the difference from discriptive models and explanatory models. Discriptive models capture datas patterns from the data but they don't provide information about why the data contais that pattern. If we are interested just to make prediction, we can use discriptive models, however if we can understantg the linguistic pattern the model should be explanatory


Extraction architecture

raw text -> tokenization -> part of speach taggling -> entity detectation -> relation detectation

